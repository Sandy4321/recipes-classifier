{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install pymystem3\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.stem.snowball import SnowballStemmer\nfrom nltk.corpus import stopwords\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.metrics import f1_score\nfrom pymystem3 import Mystem\nimport pickle\nfrom string import punctuation\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nfor dirname, _, filenames in os.walk('/kaggle'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting pymystem3\n  Downloading pymystem3-0.2.0-py3-none-any.whl (10 kB)\nRequirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from pymystem3) (2.22.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (1.24.3)\nRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (2019.11.28)\nRequirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->pymystem3) (2.8)\nInstalling collected packages: pymystem3\nSuccessfully installed pymystem3-0.2.0\n/kaggle/input/products2/products2.csv\n/kaggle/input/products3/products2.csv\n/kaggle/input/products/products.csv\n/kaggle/input/new123/products3.csv\n/kaggle/lib/kaggle/gcp.py\n/kaggle/input/products2/products2.csv\n/kaggle/input/products3/products2.csv\n/kaggle/input/products/products.csv\n/kaggle/input/new123/products3.csv\n/kaggle/working/__notebook_source__.ipynb\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"recipes=pd.read_csv('/kaggle/input/products3/products2.csv', \n                 names=['Text','t1','t2','t3'],\n                 skiprows=1,\n                 sep='|')\nrecipes.dropna(subset = [\"Text\"], inplace=True)\n#recipes.head()","execution_count":36,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes.t1.value_counts().plot(kind='bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    text = re.sub(\"\\'\", \"\", text) \n    text = re.sub(\"[^а-яА-ЯЁё]\",\" \",text) \n    text = ' '.join(text.split()) \n    text = text.lower() \n    \n    return text\n\nmystem = Mystem() \nrussian_stopwords = stopwords.words(\"russian\")\ndef preprocess_text(text):\n    tokens = mystem.lemmatize(text.lower())\n    tokens = [token for token in tokens if token not in russian_stopwords\\\n              and token != \" \" \\\n              and token.strip() not in punctuation]    \n    text = \" \".join(tokens)\n    return text\n\nstop_words = set(stopwords.words('russian'))\ndef remove_stopwords(text):\n    no_stopword_text = [w for w in text.split() if not w in stop_words]\n    return ' '.join(no_stopword_text)\n\nrecipes.clean_text = recipes.Text.apply(lambda x: clean_text(x))\n#recipes.clean_text[2]","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def freq_words(x, terms = 30): \n  all_words = ' '.join([text for text in x]) \n  all_words = all_words.split() \n  fdist = nltk.FreqDist(all_words) \n  words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())}) \n  \n  # selecting top 20 most frequent words \n  d = words_df.nlargest(columns=\"count\", n = terms) \n  \n  # visualize words and frequencies\n  plt.figure(figsize=(12,15)) \n  ax = sns.barplot(data=d, x= \"count\", y = \"word\") \n  ax.set(ylabel = 'Word') \n  plt.show()\n  \n#print 100 most frequent words \n#freq_words(recipes.clean_text, 10)","execution_count":37,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nltk.download('stopwords')","execution_count":13,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"True"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"recipes.clean_text = recipes.clean_text.apply(lambda x: remove_stopwords(x))\nrecipes.clean_text = recipes.clean_text.apply(preprocess_text)\n#freq_words(recipes.clean_text, 30)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)\nxtrain, xval, ytrain, yval = train_test_split(recipes.clean_text, recipes.t1, test_size=0.2, random_state=9)\n\nxtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\nxval_tfidf = tfidf_vectorizer.transform(xval)\n\nlr = LogisticRegression()\nclf = OneVsRestClassifier(lr)\n\nclf.fit(xtrain_tfidf, ytrain)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = clf.predict(xval_tfidf)\nf1_score(yval, y_pred, average=\"micro\")","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"0.7838307401258638"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def infer_tags(q):\n    q = clean_text(q)\n    q = remove_stopwords(q)\n    q_vec = tfidf_vectorizer.transform([q])\n    q_pred = clf.predict(q_vec)\n    return q_pred","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5): \n  k = xval.sample(1).index[0] \n  print(\"Text: \", recipes.Text[k], \"\\nPredicted text: \", infer_tags(xval[k])), print(\"Actual genre: \",recipes.t1[k], \"\\n\")","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = 'finalized_model.sav'\npickle.dump(clf, open(filename, 'wb'))\nloaded_model = pickle.load(open('/kaggle/working/finalized_model.sav', 'rb'))","execution_count":31,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def infer_tags2(q):\n    q = clean_text(q)\n    q = remove_stopwords(q)\n    q = preprocess_text(q)\n    q_vec = tfidf_vectorizer.transform([q])\n    q_pred = loaded_model.predict(q_vec)\n    return q_pred\n#infer_tags2('борщ')","execution_count":40,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pickle.dump(tfidf_vectorizer, open(\"tfidf.pickle\", \"wb\"))\ntfidf_loaded = pickle.load(open('/kaggle/working/tfidf.pickle', 'rb'))","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def infer_tags3(q):\n    q = clean_text(q)\n    q = remove_stopwords(q)\n    q = preprocess_text(q)\n    q_vec = tfidf_loaded.transform([q])\n    q_pred = loaded_model.predict(q_vec)\n    return q_pred\ninfer_tags3('Рецепт простого, быстрого и полезного перекуса! Если любите похрустеть, то это блюдо из цукини просто идеально подойдет! ')[0]","execution_count":35,"outputs":[{"output_type":"execute_result","execution_count":35,"data":{"text/plain":"'Закуски'"},"metadata":{}}]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}
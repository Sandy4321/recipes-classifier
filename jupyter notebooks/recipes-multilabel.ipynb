{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import pickle\n",
    "from string import punctuation\n",
    "\n",
    "#!pip install pymystem3\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "#import os\n",
    "#for dirname, _, filenames in os.walk('/projects/CookBook/data/'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "recipes=pd.read_csv('/projects/CookBook/data/RAW_recipes.csv',\n",
    "                   converters={'tags': lambda x: x[1:-1].replace('\"', '').replace(\"'\", \"\").replace(\" \", \"\").split(',')}\n",
    "                   )\n",
    "\n",
    "recipes[\"Text\"] = recipes[\"name\"] + ' ' + recipes[\"description\"]\n",
    "recipes = recipes.drop(['id', 'minutes','contributor_id', 'nutrition', 'n_steps', 'n_ingredients', 'submitted', 'name', 'description', 'steps', 'ingredients'], axis=1)\n",
    "#recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # remove backslash-apostrophe \n",
    "    text = re.sub(\"\\'\", \"\", text)\n",
    "    text = re.sub(\",\" , \" \", text)\n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    return text\n",
    "\n",
    "recipes.Text = recipes.Text.fillna(\" no recipe \")\n",
    "recipes.Text = recipes.Text.apply(lambda x: clean_text(x))\n",
    "#recipes.Text[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "#recipes = recipes.join(pd.DataFrame(mlb.fit_transform(recipes.pop('tags')), columns=mlb.classes_, index=recipes.index))\n",
    "#recipes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_words(x, terms = 30): \n",
    "    all_words = ' '.join([text for text in x]) \n",
    "    all_words = all_words.split() \n",
    "    fdist = nltk.FreqDist(all_words) \n",
    "    words_df = pd.DataFrame({'word':list(fdist.keys()), 'count':list(fdist.values())}) \n",
    "  \n",
    "  # selecting top 20 most frequent words \n",
    "    d = words_df.nlargest(columns=\"count\", n = terms) \n",
    "  \n",
    "  # visualize words and frequencies\n",
    "    plt.figure(figsize=(12,15)) \n",
    "    ax = sns.barplot(data=d, x= \"count\", y = \"word\") \n",
    "    ax.set(ylabel = 'Word') \n",
    "    plt.show()\n",
    "  \n",
    "  #print 100 most frequent words \n",
    "#freq_words(recipes.Text, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystem = Mystem() \n",
    "def preprocess_text(text):\n",
    "    tokens = mystem.lemmatize(text.lower())\n",
    "    tokens = [token for token in tokens if token != \" \" \\\n",
    "              and token.strip() not in punctuation]    \n",
    "    text = \" \".join(tokens)\n",
    "    return text\n",
    "\n",
    "recipes.Text = recipes.Text.apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.corpus import stopwords\n",
    "#stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "#recipes.Text = recipes.Text.apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "#freq_words(recipes.Text, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "#multilabel_binarizer = MultiLabelBinarizer()\n",
    "#multilabel_binarizer.fit(recipes.tags)\n",
    "\n",
    "# transform target variable\n",
    "y = recipes.drop(['Text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xval, ytrain, yval = train_test_split(recipes.Text, y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Binary Relevance\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Performance metric\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(max_iter = 1000)\n",
    "clf = OneVsRestClassifier(lr)\n",
    "# fit model on train data\n",
    "#clf.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(xval_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#multilabel_binarizer.inverse_transform(y_pred)[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_score(yval, y_pred, average=\"micro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_tags(q):\n",
    "    q = clean_text(q)\n",
    "    q = preprocess_text(q)\n",
    "    q = remove_stopwords(q)\n",
    "    q_vec = tfidf_vectorizer.transform([q])\n",
    "    q_pred = clf.predict(q_vec)\n",
    "    return multilabel_binarizer.inverse_transform(q_pred)\n",
    "\n",
    "#infer_tags('fried chicken')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recipes_mini=recipes.head(3)\n",
    "#recipes_mini.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def converter(x):\n",
    "    return frozenset(x) if isinstance(x, (set, list)) else x\n",
    "\n",
    "#print(len(mini.tags.apply(converter).unique()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
